{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "at7Y4NYQwO6j",
        "outputId": "240b1393-9fcc-48d9-9502-a4005d3609f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gdown in d:\\users\\dario\\onedrive\\uu\\courses\\ncml\\project ncml\\hga_feature_selection\\.venv\\lib\\site-packages (5.2.0)\n",
            "Requirement already satisfied: pandas in d:\\users\\dario\\onedrive\\uu\\courses\\ncml\\project ncml\\hga_feature_selection\\.venv\\lib\\site-packages (2.2.3)\n",
            "Requirement already satisfied: numpy in d:\\users\\dario\\onedrive\\uu\\courses\\ncml\\project ncml\\hga_feature_selection\\.venv\\lib\\site-packages (2.2.5)\n",
            "Collecting scikit-learn\n",
            "  Downloading scikit_learn-1.6.1-cp312-cp312-win_amd64.whl.metadata (15 kB)\n",
            "Collecting matplotlib\n",
            "  Downloading matplotlib-3.10.1-cp312-cp312-win_amd64.whl.metadata (11 kB)\n",
            "Collecting seaborn\n",
            "  Downloading seaborn-0.13.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Requirement already satisfied: beautifulsoup4 in d:\\users\\dario\\onedrive\\uu\\courses\\ncml\\project ncml\\hga_feature_selection\\.venv\\lib\\site-packages (from gdown) (4.13.4)\n",
            "Requirement already satisfied: filelock in d:\\users\\dario\\onedrive\\uu\\courses\\ncml\\project ncml\\hga_feature_selection\\.venv\\lib\\site-packages (from gdown) (3.18.0)\n",
            "Requirement already satisfied: requests[socks] in d:\\users\\dario\\onedrive\\uu\\courses\\ncml\\project ncml\\hga_feature_selection\\.venv\\lib\\site-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in d:\\users\\dario\\onedrive\\uu\\courses\\ncml\\project ncml\\hga_feature_selection\\.venv\\lib\\site-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in d:\\users\\dario\\onedrive\\uu\\courses\\ncml\\project ncml\\hga_feature_selection\\.venv\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in d:\\users\\dario\\onedrive\\uu\\courses\\ncml\\project ncml\\hga_feature_selection\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in d:\\users\\dario\\onedrive\\uu\\courses\\ncml\\project ncml\\hga_feature_selection\\.venv\\lib\\site-packages (from pandas) (2025.2)\n",
            "Collecting scipy>=1.6.0 (from scikit-learn)\n",
            "  Downloading scipy-1.15.2-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
            "Collecting joblib>=1.2.0 (from scikit-learn)\n",
            "  Downloading joblib-1.5.0-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
            "  Downloading threadpoolctl-3.6.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting contourpy>=1.0.1 (from matplotlib)\n",
            "  Downloading contourpy-1.3.2-cp312-cp312-win_amd64.whl.metadata (5.5 kB)\n",
            "Collecting cycler>=0.10 (from matplotlib)\n",
            "  Using cached cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib)\n",
            "  Downloading fonttools-4.57.0-cp312-cp312-win_amd64.whl.metadata (104 kB)\n",
            "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
            "  Downloading kiwisolver-1.4.8-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
            "Requirement already satisfied: packaging>=20.0 in d:\\users\\dario\\onedrive\\uu\\courses\\ncml\\project ncml\\hga_feature_selection\\.venv\\lib\\site-packages (from matplotlib) (25.0)\n",
            "Collecting pillow>=8 (from matplotlib)\n",
            "  Downloading pillow-11.2.1-cp312-cp312-win_amd64.whl.metadata (9.1 kB)\n",
            "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
            "  Downloading pyparsing-3.2.3-py3-none-any.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: six>=1.5 in d:\\users\\dario\\onedrive\\uu\\courses\\ncml\\project ncml\\hga_feature_selection\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in d:\\users\\dario\\onedrive\\uu\\courses\\ncml\\project ncml\\hga_feature_selection\\.venv\\lib\\site-packages (from beautifulsoup4->gdown) (2.7)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in d:\\users\\dario\\onedrive\\uu\\courses\\ncml\\project ncml\\hga_feature_selection\\.venv\\lib\\site-packages (from beautifulsoup4->gdown) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\users\\dario\\onedrive\\uu\\courses\\ncml\\project ncml\\hga_feature_selection\\.venv\\lib\\site-packages (from requests[socks]->gdown) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in d:\\users\\dario\\onedrive\\uu\\courses\\ncml\\project ncml\\hga_feature_selection\\.venv\\lib\\site-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in d:\\users\\dario\\onedrive\\uu\\courses\\ncml\\project ncml\\hga_feature_selection\\.venv\\lib\\site-packages (from requests[socks]->gdown) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in d:\\users\\dario\\onedrive\\uu\\courses\\ncml\\project ncml\\hga_feature_selection\\.venv\\lib\\site-packages (from requests[socks]->gdown) (2025.4.26)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in d:\\users\\dario\\onedrive\\uu\\courses\\ncml\\project ncml\\hga_feature_selection\\.venv\\lib\\site-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Requirement already satisfied: colorama in d:\\users\\dario\\onedrive\\uu\\courses\\ncml\\project ncml\\hga_feature_selection\\.venv\\lib\\site-packages (from tqdm->gdown) (0.4.6)\n",
            "Downloading scikit_learn-1.6.1-cp312-cp312-win_amd64.whl (11.1 MB)\n",
            "   ---------------------------------------- 0.0/11.1 MB ? eta -:--:--\n",
            "   - -------------------------------------- 0.5/11.1 MB 2.8 MB/s eta 0:00:04\n",
            "   ---- ----------------------------------- 1.3/11.1 MB 3.7 MB/s eta 0:00:03\n",
            "   --------- ------------------------------ 2.6/11.1 MB 4.6 MB/s eta 0:00:02\n",
            "   ---------------- ----------------------- 4.5/11.1 MB 5.7 MB/s eta 0:00:02\n",
            "   -------------------------- ------------- 7.3/11.1 MB 7.3 MB/s eta 0:00:01\n",
            "   -------------------------------------- - 10.7/11.1 MB 8.9 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 11.1/11.1 MB 9.0 MB/s eta 0:00:00\n",
            "Downloading matplotlib-3.10.1-cp312-cp312-win_amd64.whl (8.1 MB)\n",
            "   ---------------------------------------- 0.0/8.1 MB ? eta -:--:--\n",
            "   --------------- ------------------------ 3.1/8.1 MB 15.3 MB/s eta 0:00:01\n",
            "   ----------------------------------- ---- 7.1/8.1 MB 17.4 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 8.1/8.1 MB 16.6 MB/s eta 0:00:00\n",
            "Downloading seaborn-0.13.2-py3-none-any.whl (294 kB)\n",
            "Downloading contourpy-1.3.2-cp312-cp312-win_amd64.whl (223 kB)\n",
            "Using cached cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
            "Downloading fonttools-4.57.0-cp312-cp312-win_amd64.whl (2.2 MB)\n",
            "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
            "   ---------------------------------------- 2.2/2.2 MB 17.7 MB/s eta 0:00:00\n",
            "Downloading joblib-1.5.0-py3-none-any.whl (307 kB)\n",
            "Downloading kiwisolver-1.4.8-cp312-cp312-win_amd64.whl (71 kB)\n",
            "Downloading pillow-11.2.1-cp312-cp312-win_amd64.whl (2.7 MB)\n",
            "   ---------------------------------------- 0.0/2.7 MB ? eta -:--:--\n",
            "   ---------------------------------------- 2.7/2.7 MB 15.4 MB/s eta 0:00:00\n",
            "Downloading pyparsing-3.2.3-py3-none-any.whl (111 kB)\n",
            "Downloading scipy-1.15.2-cp312-cp312-win_amd64.whl (40.9 MB)\n",
            "   ---------------------------------------- 0.0/40.9 MB ? eta -:--:--\n",
            "   --- ------------------------------------ 3.7/40.9 MB 16.8 MB/s eta 0:00:03\n",
            "   ------ --------------------------------- 6.8/40.9 MB 16.1 MB/s eta 0:00:03\n",
            "   ---------- ----------------------------- 11.0/40.9 MB 17.2 MB/s eta 0:00:02\n",
            "   -------------- ------------------------- 15.2/40.9 MB 17.7 MB/s eta 0:00:02\n",
            "   ------------------ --------------------- 19.4/40.9 MB 18.3 MB/s eta 0:00:02\n",
            "   ---------------------- ----------------- 23.3/40.9 MB 18.2 MB/s eta 0:00:01\n",
            "   -------------------------- ------------- 27.5/40.9 MB 18.4 MB/s eta 0:00:01\n",
            "   ------------------------------ --------- 31.7/40.9 MB 18.5 MB/s eta 0:00:01\n",
            "   ---------------------------------- ----- 35.7/40.9 MB 18.4 MB/s eta 0:00:01\n",
            "   ------------------------------------- -- 38.3/40.9 MB 18.2 MB/s eta 0:00:01\n",
            "   ---------------------------------------- 40.9/40.9 MB 17.7 MB/s eta 0:00:00\n",
            "Downloading threadpoolctl-3.6.0-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: threadpoolctl, scipy, pyparsing, pillow, kiwisolver, joblib, fonttools, cycler, contourpy, scikit-learn, matplotlib, seaborn\n",
            "\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   --- ------------------------------------  1/12 [scipy]\n",
            "   ------ ---------------------------------  2/12 [pyparsing]\n",
            "   ---------- -----------------------------  3/12 [pillow]\n",
            "   ---------- -----------------------------  3/12 [pillow]\n",
            "   ---------- -----------------------------  3/12 [pillow]\n",
            "   ---------- -----------------------------  3/12 [pillow]\n",
            "   ---------------- -----------------------  5/12 [joblib]\n",
            "   ---------------- -----------------------  5/12 [joblib]\n",
            "   -------------------- -------------------  6/12 [fonttools]\n",
            "   -------------------- -------------------  6/12 [fonttools]\n",
            "   -------------------- -------------------  6/12 [fonttools]\n",
            "   -------------------- -------------------  6/12 [fonttools]\n",
            "   -------------------- -------------------  6/12 [fonttools]\n",
            "   -------------------- -------------------  6/12 [fonttools]\n",
            "   -------------------- -------------------  6/12 [fonttools]\n",
            "   -------------------- -------------------  6/12 [fonttools]\n",
            "   -------------------- -------------------  6/12 [fonttools]\n",
            "   -------------------- -------------------  6/12 [fonttools]\n",
            "   -------------------- -------------------  6/12 [fonttools]\n",
            "   -------------------- -------------------  6/12 [fonttools]\n",
            "   -------------------- -------------------  6/12 [fonttools]\n",
            "   ------------------------------ ---------  9/12 [scikit-learn]\n",
            "   ------------------------------ ---------  9/12 [scikit-learn]\n",
            "   ------------------------------ ---------  9/12 [scikit-learn]\n",
            "   ------------------------------ ---------  9/12 [scikit-learn]\n",
            "   ------------------------------ ---------  9/12 [scikit-learn]\n",
            "   ------------------------------ ---------  9/12 [scikit-learn]\n",
            "   ------------------------------ ---------  9/12 [scikit-learn]\n",
            "   ------------------------------ ---------  9/12 [scikit-learn]\n",
            "   ------------------------------ ---------  9/12 [scikit-learn]\n",
            "   ------------------------------ ---------  9/12 [scikit-learn]\n",
            "   ------------------------------ ---------  9/12 [scikit-learn]\n",
            "   ------------------------------ ---------  9/12 [scikit-learn]\n",
            "   ------------------------------ ---------  9/12 [scikit-learn]\n",
            "   ------------------------------ ---------  9/12 [scikit-learn]\n",
            "   ------------------------------ ---------  9/12 [scikit-learn]\n",
            "   ------------------------------ ---------  9/12 [scikit-learn]\n",
            "   ------------------------------ ---------  9/12 [scikit-learn]\n",
            "   ------------------------------ ---------  9/12 [scikit-learn]\n",
            "   ------------------------------ ---------  9/12 [scikit-learn]\n",
            "   ------------------------------ ---------  9/12 [scikit-learn]\n",
            "   ------------------------------ ---------  9/12 [scikit-learn]\n",
            "   ------------------------------ ---------  9/12 [scikit-learn]\n",
            "   ------------------------------ ---------  9/12 [scikit-learn]\n",
            "   ------------------------------ ---------  9/12 [scikit-learn]\n",
            "   --------------------------------- ------ 10/12 [matplotlib]\n",
            "   --------------------------------- ------ 10/12 [matplotlib]\n",
            "   --------------------------------- ------ 10/12 [matplotlib]\n",
            "   --------------------------------- ------ 10/12 [matplotlib]\n",
            "   --------------------------------- ------ 10/12 [matplotlib]\n",
            "   --------------------------------- ------ 10/12 [matplotlib]\n",
            "   --------------------------------- ------ 10/12 [matplotlib]\n",
            "   --------------------------------- ------ 10/12 [matplotlib]\n",
            "   --------------------------------- ------ 10/12 [matplotlib]\n",
            "   --------------------------------- ------ 10/12 [matplotlib]\n",
            "   --------------------------------- ------ 10/12 [matplotlib]\n",
            "   --------------------------------- ------ 10/12 [matplotlib]\n",
            "   --------------------------------- ------ 10/12 [matplotlib]\n",
            "   --------------------------------- ------ 10/12 [matplotlib]\n",
            "   --------------------------------- ------ 10/12 [matplotlib]\n",
            "   --------------------------------- ------ 10/12 [matplotlib]\n",
            "   ------------------------------------ --- 11/12 [seaborn]\n",
            "   ------------------------------------ --- 11/12 [seaborn]\n",
            "   ---------------------------------------- 12/12 [seaborn]\n",
            "\n",
            "Successfully installed contourpy-1.3.2 cycler-0.12.1 fonttools-4.57.0 joblib-1.5.0 kiwisolver-1.4.8 matplotlib-3.10.1 pillow-11.2.1 pyparsing-3.2.3 scikit-learn-1.6.1 scipy-1.15.2 seaborn-0.13.2 threadpoolctl-3.6.0\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "# --- 0. Install necessary library ---\n",
        "#changed as recommended approach (!pip)-->(%pip) which equals to: python -m pip install <module>\n",
        "%pip install gdown pandas numpy scikit-learn matplotlib seaborn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "m8pP3LbUwO38"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import StandardScaler # Keep for potential future use\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import gdown # Library to download from Google Drive\n",
        "from sklearn.impute import SimpleImputer # Import imputer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "szfFNuoUwO1G",
        "outputId": "f8e32269-12d5-4b4c-9c05-47af3ea7f35e"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --- 1. Download Data from Google Drive ---\n",
        "file_id = '1dRE9RSdR3pCnDbr5iYHfH2sdR4hOdG3H'\n",
        "output_file = 'synthetic_data_loaded_with_header.csv' # Changed filename for clarity\n",
        "url = f'https://drive.google.com/uc?id={file_id}'\n",
        "\n",
        "print(f\"Downloading file from Google Drive (ID: {file_id})...\")\n",
        "try:\n",
        "    # Using fuzzy=True might help if the direct download link changes slightly\n",
        "    gdown.download(url, output_file, quiet=False, fuzzy=True)\n",
        "    print(f\"File saved as {output_file}\")\n",
        "except Exception as e:\n",
        "    print(f\"Failed to download file: {e}\")\n",
        "    exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yHfX4xZuwOxq",
        "outputId": "5f236e2a-16f0-4e78-962e-f246052d4606"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Data loaded successfully from synthetic_data_loaded_with_header.csv with shape: (500, 590)\n",
            "\n",
            "First 5 rows of loaded data:\n",
            "   feature_0  feature_1  feature_2  feature_3  feature_4  feature_5  \\\n",
            "0    2996.01    2500.01  2194.6444  1116.2950     1.3529      100.0   \n",
            "1    3062.47    2494.43  2160.3667  1302.6607     1.4656      100.0   \n",
            "2    3024.75    2288.05  2257.1667  1437.5003     1.6769      100.0   \n",
            "3    2971.75    2462.09  2244.1111  1969.7867     1.2678      100.0   \n",
            "4    2898.08    2484.55  2207.0444  1085.3232     1.1369      100.0   \n",
            "\n",
            "   feature_6  feature_7  feature_8  feature_9  ...  feature_580  feature_581  \\\n",
            "0   103.0567     0.1195     1.5362     0.0104  ...       0.0052     737.3048   \n",
            "1    98.1244     0.1253     1.5291    -0.0038  ...       0.0031      55.8468   \n",
            "2    98.6889     0.1246     1.2956     0.0088  ...       0.0066     112.8617   \n",
            "3   100.9333     0.1233     1.4826    -0.0106  ...       0.0040      46.4594   \n",
            "4    98.0211     0.1214     1.6030    -0.0047  ...       0.0079     116.6826   \n",
            "\n",
            "   feature_582  feature_583  feature_584  feature_585  feature_586  \\\n",
            "0       0.4988       0.0215       0.0028       2.5621       0.0102   \n",
            "1       0.4981       0.0116       0.0025       3.8122       0.0289   \n",
            "2       0.5036       0.0134       0.0045       2.6765       0.0208   \n",
            "3       0.5025       0.0113       0.0030       2.8893       0.0325   \n",
            "4       0.5007       0.0107       0.0035       2.6974       0.0218   \n",
            "\n",
            "   feature_587  feature_588  feature_589  \n",
            "0       0.0298       0.0031      42.7294  \n",
            "1       0.0051       0.0061      56.1631  \n",
            "2       0.0112       0.0030      56.7050  \n",
            "3       0.0114       0.0032      57.7824  \n",
            "4       0.0117       0.0033      62.7655  \n",
            "\n",
            "[5 rows x 590 columns]\n",
            "\n",
            "Data info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 500 entries, 0 to 499\n",
            "Columns: 590 entries, feature_0 to feature_589\n",
            "dtypes: float64(590)\n",
            "memory usage: 2.3 MB\n"
          ]
        }
      ],
      "source": [
        "# --- 2. Load Data using Pandas (Assuming Header IS Present) ---\n",
        "try:\n",
        "    # FIX: Remove header=None to let Pandas read the first row as header\n",
        "    data = pd.read_csv(output_file)\n",
        "    print(f\"Data loaded successfully from {output_file} with shape: {data.shape}\")\n",
        "    # Display first few rows and info to check data types\n",
        "    print(\"\\nFirst 5 rows of loaded data:\")\n",
        "    print(data.head())\n",
        "    print(\"\\nData info:\")\n",
        "    data.info()\n",
        "except Exception as e:\n",
        "    print(f\"Failed to load data from {output_file}: {e}\")\n",
        "    exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jn6x0zd5wOu5",
        "outputId": "2ab6778d-5717-4a80-99d4-ec829d0b7389"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Feature names extracted from header: ['feature_0', 'feature_1', 'feature_2', 'feature_3', 'feature_4']... (Total: 589)\n",
            "Features shape after cleaning: (500, 589)\n",
            "Target shape after cleaning: (500,)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "# --- 3. Prepare Data ---\n",
        "if data.shape[1] > 1:\n",
        "    # Assume last column is target 'y', all others are features 'X'\n",
        "    feature_names = data.columns[:-1].tolist() # Get actual feature names from header\n",
        "    X_df = data[feature_names] # Select feature columns using names\n",
        "    y_series = data.iloc[:, -1] # Select target column by position\n",
        "\n",
        "    print(f\"\\nFeature names extracted from header: {feature_names[:5]}... (Total: {len(feature_names)})\")\n",
        "\n",
        "    # --- Keep Robust Cleaning Steps ---\n",
        "    # Convert to numeric, coercing errors (handles potential non-numeric strings WITHIN data)\n",
        "    X_df_numeric = X_df.apply(pd.to_numeric, errors='coerce')\n",
        "    y_series_numeric = pd.to_numeric(y_series, errors='coerce')\n",
        "\n",
        "    # Handle potential NaN values resulting from coercion or missing values in original file\n",
        "    imputer_X = SimpleImputer(strategy='mean')\n",
        "    X_imputed = imputer_X.fit_transform(X_df_numeric)\n",
        "\n",
        "    imputer_y = SimpleImputer(strategy='mean')\n",
        "    y_imputed = imputer_y.fit_transform(y_series_numeric.values.reshape(-1, 1)).flatten()\n",
        "\n",
        "    # Check for NaNs after imputation (should only happen if a whole column was non-numeric/NaN)\n",
        "    if np.isnan(X_imputed).any() or np.isnan(y_imputed).any():\n",
        "        print(\"Warning: NaNs still present after imputation. Check columns with all invalid values.\")\n",
        "        # Consider more advanced imputation or dropping problematic columns/rows if this occurs\n",
        "\n",
        "    X = X_imputed\n",
        "    y = y_imputed\n",
        "\n",
        "    print(f\"Features shape after cleaning: {X.shape}\")\n",
        "    print(f\"Target shape after cleaning: {y.shape}\")\n",
        "    n_features_loaded = X.shape[1] # Keep track of the number of features\n",
        "\n",
        "else:\n",
        "    print(\"Error: Loaded data has only one column. Cannot separate features and target.\")\n",
        "    exit()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-goCXrEowOrh",
        "outputId": "c1782c36-b773-442e-eee8-274b2a701ad0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Training features shape: (350, 589)\n",
            "Validation features shape: (150, 589)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# --- 4. Split Data for Fitness Evaluation ---\n",
        "# Using the cleaned X and y, with stratify helps maintain the proportion of class labels\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)\n",
        "n_features = X_train.shape[1] # Use the actual number of features\n",
        "print(f\"\\nTraining features shape: {X_train.shape}\")\n",
        "print(f\"Validation features shape: {X_val.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qxQhWy3awObl"
      },
      "outputs": [],
      "source": [
        "# --- 5. Hybrid Genetic Algorithm for Feature Selection ---\n",
        "\n",
        "# GA Parameters (TUNED for potentially faster runtime)\n",
        "# --- TUNING POINT ---\n",
        "POP_SIZE = 25 # Reduced from 30\n",
        "N_GEN = 20    # Reduced from 30\n",
        "# --- TUNING POINT ---\n",
        "CROSSOVER_RATE = 0.8 # Kept the same\n",
        "MUTATION_RATE = 0.1  # Kept the same\n",
        "ELITISM = True       # Kept the same\n",
        "N_ELITE = 1          # Kept the same\n",
        "# --- TUNING POINT ---\n",
        "LOCAL_SEARCH_STEPS = 2 # Reduced from 5\n",
        "LS_TOP_K = 2          # Reduced from 3\n",
        "# --- TUNING POINT ---\n",
        "PENALTY_COEFF = 0.01   # Kept the same\n",
        "\n",
        "# --- Fitness Function (using Random Forest) ---\n",
        "def fitness_function(individual):\n",
        "    selected_indices = np.where(individual == 1)[0] # Get indices where bit is 1\n",
        "    num_selected = len(selected_indices)\n",
        "\n",
        "    if num_selected == 0:\n",
        "        return -np.inf # Heavily penalize empty feature set\n",
        "\n",
        "    # Select corresponding columns from train/validation sets\n",
        "    X_train_sel = X_train[:, selected_indices]\n",
        "    X_val_sel = X_val[:, selected_indices]\n",
        "\n",
        "    # Check for NaNs *before* fitting (added robustness)\n",
        "    if np.isnan(X_train_sel).any() or np.isnan(y_train).any() or np.isnan(X_val_sel).any():\n",
        "         # This case should ideally not happen after imputation, but good safeguard\n",
        "         print(\"Warning: NaN detected in data subset for fitness evaluation.\")\n",
        "         return -np.inf # Penalize subsets leading to NaNs\n",
        "\n",
        "    # Train and evaluate Random Forest\n",
        "    # --- TUNING POINT ---\n",
        "    # Use fewer estimators for significantly faster fitness evaluation\n",
        "    model = RandomForestRegressor(n_estimators=15, # Reduced from 50\n",
        "                                  random_state=42,\n",
        "                                  n_jobs=-1) # Use n_jobs=-1 for parallelization\n",
        "    # --- TUNING POINT ---\n",
        "    try:\n",
        "        model.fit(X_train_sel, y_train)\n",
        "        y_pred = model.predict(X_val_sel)\n",
        "        mse = mean_squared_error(y_val, y_pred)\n",
        "        # Fitness = Negative MSE (maximization) - Penalty for feature count\n",
        "        fitness = -mse - PENALTY_COEFF * num_selected\n",
        "    except ValueError as e:\n",
        "        # Catch potential errors during fitting/prediction if data issues remain\n",
        "        print(f\"Error during model fitting/prediction: {e}\")\n",
        "        fitness = -np.inf # Penalize if model fails\n",
        "    return fitness\n",
        "\n",
        "# --- GA Operators (Initialization, Selection, Crossover, Mutation) ---\n",
        "# (These functions remain unchanged structurally)\n",
        "def initialize_population(pop_size, n_features):\n",
        "    pop = np.random.randint(0, 2, size=(pop_size, n_features))\n",
        "    # Ensure initial individuals are not all zeros\n",
        "    for i in range(pop_size):\n",
        "        if np.sum(pop[i]) == 0:\n",
        "            if n_features > 0: # Avoid error if n_features is 0\n",
        "                pop[i, np.random.randint(0, n_features)] = 1\n",
        "    return pop\n",
        "\n",
        "def tournament_selection(pop, fitnesses, k=3):\n",
        "    # Handle potential -inf fitness values gracefully\n",
        "    valid_indices = np.where(np.isfinite(fitnesses))[0]\n",
        "    if len(valid_indices) == 0:\n",
        "        # If no individuals have valid fitness, return random individuals to avoid crash\n",
        "        print(\"Warning: No individuals with valid fitness in selection.\")\n",
        "        return pop[np.random.choice(len(pop), size=len(pop))]\n",
        "    if len(valid_indices) < k:\n",
        "        # If fewer valid individuals than tournament size, select randomly from valid ones\n",
        "        selected_idx = np.random.choice(valid_indices, size=len(pop), replace=True) # Allow replacement\n",
        "        return pop[selected_idx]\n",
        "\n",
        "    selected = []\n",
        "    for _ in range(len(pop)):\n",
        "       # Ensure tournament participants are chosen only from valid individuals\n",
        "       tournament_contenders_indices = np.random.choice(valid_indices, k, replace=False)\n",
        "       winner_idx_in_contenders = np.argmax(fitnesses[tournament_contenders_indices])\n",
        "       winner_original_idx = tournament_contenders_indices[winner_idx_in_contenders]\n",
        "       selected.append(pop[winner_original_idx])\n",
        "    return np.array(selected)\n",
        "\n",
        "def uniform_crossover(parent1, parent2):\n",
        "    mask = np.random.randint(0, 2, size=len(parent1), dtype=bool)\n",
        "    child = np.where(mask, parent1, parent2)\n",
        "    return child\n",
        "\n",
        "def mutate(individual, mutation_rate):\n",
        "    mutant = individual.copy()\n",
        "    mutation_mask = np.random.rand(len(mutant)) < mutation_rate\n",
        "    mutant[mutation_mask] = 1 - mutant[mutation_mask] # Flip bits\n",
        "    # Ensure mutation doesn't result in an all-zero individual\n",
        "    if np.sum(mutant) == 0 and len(mutant) > 0:\n",
        "         mutant[np.random.randint(0, len(mutant))] = 1\n",
        "    return mutant\n",
        "\n",
        "# --- Local Search ---\n",
        "# (This function remains unchanged structurally)\n",
        "def local_search(individual, fitness_func, steps=LOCAL_SEARCH_STEPS): # Uses tuned steps\n",
        "    best = individual.copy()\n",
        "    current_fitness = fitness_func(best)\n",
        "    # Cannot perform local search on invalid individual\n",
        "    if not np.isfinite(current_fitness):\n",
        "        return best\n",
        "\n",
        "    indices_to_try = np.arange(len(best))\n",
        "    for _ in range(steps):\n",
        "        np.random.shuffle(indices_to_try)\n",
        "        improved_in_step = False\n",
        "        for idx in indices_to_try:\n",
        "            candidate = best.copy()\n",
        "            candidate[idx] = 1 - candidate[idx] # Flip bit\n",
        "            # Ensure candidate is not all zeros\n",
        "            if np.sum(candidate) == 0:\n",
        "                continue # Skip invalid (all zero) candidate\n",
        "            candidate_fitness = fitness_func(candidate)\n",
        "            # Only accept improvement if candidate_fitness is valid and better\n",
        "            if np.isfinite(candidate_fitness) and candidate_fitness > current_fitness:\n",
        "                best = candidate\n",
        "                current_fitness = candidate_fitness\n",
        "                improved_in_step = True\n",
        "                break # Move to next step once an improvement is found (first improvement)\n",
        "        if not improved_in_step:\n",
        "            break # Stop if no single flip improved fitness in a full pass\n",
        "    return best\n",
        "\n",
        "# --- Main HGA Loop ---\n",
        "# (This function remains unchanged structurally, but uses the tuned parameters)\n",
        "def hybrid_ga_feature_selection():\n",
        "    population = initialize_population(POP_SIZE, n_features)\n",
        "    best_fitnesses = []\n",
        "    best_individual_overall = None\n",
        "    best_fit_overall = -np.inf\n",
        "    features_selected_history = []\n",
        "\n",
        "    print(\"\\nStarting Hybrid Genetic Algorithm...\")\n",
        "    for gen in range(N_GEN): # Uses tuned N_GEN\n",
        "        # Evaluate fitness for the current population\n",
        "        fitnesses = np.array([fitness_function(ind) for ind in population])\n",
        "\n",
        "        # Find best valid individual in generation\n",
        "        valid_fitness_indices = np.where(np.isfinite(fitnesses))[0]\n",
        "        if len(valid_fitness_indices) == 0:\n",
        "            print(f\"Warning: No valid individuals in generation {gen+1}. Stopping early.\")\n",
        "            # Keep the last known best if available, otherwise end with None\n",
        "            best_fitnesses.append(best_fit_overall if np.isfinite(best_fit_overall) else np.nan)\n",
        "            features_selected_history.append(np.sum(best_individual_overall) if best_individual_overall is not None else 0)\n",
        "            break # Stop the GA run\n",
        "\n",
        "        gen_best_idx_among_valid = np.argmax(fitnesses[valid_fitness_indices])\n",
        "        gen_best_original_idx = valid_fitness_indices[gen_best_idx_among_valid]\n",
        "        gen_best_fitness = fitnesses[gen_best_original_idx]\n",
        "\n",
        "        # Update overall best\n",
        "        if gen_best_fitness > best_fit_overall:\n",
        "            best_fit_overall = gen_best_fitness\n",
        "            best_individual_overall = population[gen_best_original_idx].copy()\n",
        "\n",
        "        # Store history based on overall best\n",
        "        best_fitnesses.append(best_fit_overall)\n",
        "        features_selected_history.append(np.sum(best_individual_overall) if best_individual_overall is not None else 0)\n",
        "\n",
        "        # Elitism\n",
        "        if ELITISM:\n",
        "             sorted_valid_indices = valid_fitness_indices[np.argsort(fitnesses[valid_fitness_indices])]\n",
        "             elite_indices = sorted_valid_indices[-N_ELITE:]\n",
        "             elites = population[elite_indices].copy()\n",
        "        else:\n",
        "             elites = np.empty((0, n_features), dtype=int)\n",
        "\n",
        "        # Selection\n",
        "        selected_parents = tournament_selection(population, fitnesses)\n",
        "\n",
        "        # Crossover & Mutation\n",
        "        offspring = np.empty_like(population)\n",
        "        for i in range(0, POP_SIZE, 2): # Uses tuned POP_SIZE\n",
        "            p1_idx, p2_idx = i, (i + 1) % POP_SIZE\n",
        "            parent1, parent2 = selected_parents[p1_idx], selected_parents[p2_idx]\n",
        "            if np.random.rand() < CROSSOVER_RATE:\n",
        "                child1 = uniform_crossover(parent1, parent2)\n",
        "                child2 = uniform_crossover(parent2, parent1)\n",
        "            else:\n",
        "                child1, child2 = parent1.copy(), parent2.copy()\n",
        "            offspring[i] = mutate(child1, MUTATION_RATE)\n",
        "            if i + 1 < POP_SIZE:\n",
        "                offspring[i+1] = mutate(child2, MUTATION_RATE)\n",
        "\n",
        "        # Local Search on top K individuals (uses tuned LS_TOP_K)\n",
        "        fitnesses_offspring_pre_ls = np.array([fitness_function(ind) for ind in offspring])\n",
        "        valid_offspring_indices = np.where(np.isfinite(fitnesses_offspring_pre_ls))[0]\n",
        "\n",
        "        if len(valid_offspring_indices) > 0:\n",
        "             sorted_valid_offspring_indices = valid_offspring_indices[np.argsort(fitnesses_offspring_pre_ls[valid_offspring_indices])]\n",
        "             top_indices_for_ls = sorted_valid_offspring_indices[-LS_TOP_K:] # Uses tuned LS_TOP_K\n",
        "             for idx in top_indices_for_ls:\n",
        "                 # Uses tuned LOCAL_SEARCH_STEPS inside the function call\n",
        "                 offspring[idx] = local_search(offspring[idx], fitness_function) # steps uses default from parameter\n",
        "\n",
        "        # Replacement with Elitism\n",
        "        if ELITISM and len(elites) > 0:\n",
        "            fitnesses_offspring_post_ls = np.array([fitness_function(ind) for ind in offspring])\n",
        "            valid_offspring_indices_post_ls = np.where(np.isfinite(fitnesses_offspring_post_ls))[0]\n",
        "            if len(valid_offspring_indices_post_ls) >= N_ELITE:\n",
        "                sorted_valid_offspring_indices_post_ls = valid_offspring_indices_post_ls[np.argsort(fitnesses_offspring_post_ls[valid_offspring_indices_post_ls])]\n",
        "                worst_indices = sorted_valid_offspring_indices_post_ls[:N_ELITE]\n",
        "                num_to_replace = min(len(worst_indices), len(elites))\n",
        "                offspring[worst_indices[:num_to_replace]] = elites[:num_to_replace]\n",
        "\n",
        "        population = offspring\n",
        "\n",
        "        current_best_features = np.sum(best_individual_overall) if best_individual_overall is not None else 0\n",
        "        print(f\"Generation {gen+1}/{N_GEN}: Best Fitness = {best_fit_overall:.4f}, Features Selected = {current_best_features}\")\n",
        "\n",
        "    print(\"Hybrid Genetic Algorithm finished.\")\n",
        "    return best_individual_overall, best_fitnesses, features_selected_history\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l-SDv6h_wjlE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zj3nYqt40ovq",
        "outputId": "7ee3ea7b-a0bc-44c2-fba8-e107ae167d43"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Starting Hybrid Genetic Algorithm...\n",
            "Generation 1/30: Best Fitness = -9622.4052, Features Selected = 306\n",
            "Generation 2/30: Best Fitness = -9271.5723, Features Selected = 306\n",
            "Generation 3/30: Best Fitness = -9271.5723, Features Selected = 306\n",
            "Generation 4/30: Best Fitness = -9271.5723, Features Selected = 306\n",
            "Generation 5/30: Best Fitness = -8850.7527, Features Selected = 299\n",
            "Generation 6/30: Best Fitness = -8850.7527, Features Selected = 299\n",
            "Generation 7/30: Best Fitness = -8850.7527, Features Selected = 299\n",
            "Generation 8/30: Best Fitness = -8850.7527, Features Selected = 299\n",
            "Generation 9/30: Best Fitness = -8850.7527, Features Selected = 299\n",
            "Generation 10/30: Best Fitness = -8850.7527, Features Selected = 299\n",
            "Generation 11/30: Best Fitness = -8850.7527, Features Selected = 299\n",
            "Generation 12/30: Best Fitness = -8850.7527, Features Selected = 299\n",
            "Generation 13/30: Best Fitness = -8850.7527, Features Selected = 299\n",
            "Generation 14/30: Best Fitness = -8850.7527, Features Selected = 299\n",
            "Generation 15/30: Best Fitness = -8850.7527, Features Selected = 299\n",
            "Generation 16/30: Best Fitness = -8850.7527, Features Selected = 299\n",
            "Generation 17/30: Best Fitness = -8850.7527, Features Selected = 299\n",
            "Generation 18/30: Best Fitness = -8850.7527, Features Selected = 299\n",
            "Generation 19/30: Best Fitness = -8850.7527, Features Selected = 299\n",
            "Generation 20/30: Best Fitness = -8850.7527, Features Selected = 299\n",
            "Generation 21/30: Best Fitness = -8850.7527, Features Selected = 299\n",
            "Generation 22/30: Best Fitness = -8850.7527, Features Selected = 299\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# --- 6. Run the Hybrid GA ---\n",
        "best_solution, fitness_history, features_selected_history = hybrid_ga_feature_selection()\n",
        "\n",
        "# --- 7. Results ---\n",
        "if best_solution is not None:\n",
        "    selected_feature_indices = np.where(best_solution == 1)[0]\n",
        "    print(\"\\n--- HGA Results ---\")\n",
        "    print(\"Best feature subset found:\")\n",
        "    print(\"Selected feature indices:\", selected_feature_indices)\n",
        "    # Use ACTUAL feature names from the header\n",
        "    selected_names = [feature_names[i] for i in selected_feature_indices]\n",
        "    print(\"Selected feature names:\", selected_names)\n",
        "    print(\"Number of features selected:\", len(selected_feature_indices))\n",
        "    print(f\"Final Best Fitness: {fitness_history[-1]:.4f}\")\n",
        "else:\n",
        "    print(\"\\nNo solution found or algorithm stopped early.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Av017jN2wpW3"
      },
      "outputs": [],
      "source": [
        "\n",
        "# --- 8. Plot Fitness Curve and Number of Features Selected ---\n",
        "if best_solution is not None and fitness_history and features_selected_history:\n",
        "    generations = range(1, len(fitness_history) + 1)\n",
        "    plt.figure(figsize=(14, 6))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(generations, fitness_history, marker='o', linestyle='-')\n",
        "    plt.xlabel('Generation')\n",
        "    plt.ylabel('Best Fitness')\n",
        "    plt.title('HGA Convergence: Best Fitness per Generation')\n",
        "    plt.grid(True)\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(generations, features_selected_history, marker='s', linestyle='-', color='orange')\n",
        "    plt.xlabel('Generation')\n",
        "    plt.ylabel('Number of Features Selected')\n",
        "    plt.title('HGA: Number of Features in Best Solution per Generation')\n",
        "    plt.grid(True)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"Cannot plot results as no valid solution was found or history is empty.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E-tDANHJwLd_"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
